\documentclass{article}
% =======PACKAGES=======
% FORMATTING
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{breqn}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{setspace}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Traveling Salesman Problem Approaches},
    pdfpagemode=FullScreen,
}

%\usepackage{algorithm2e}

\usepackage[margin=0.625in]{geometry}
\usepackage{parskip, setspace}
\setstretch{1.15}
\renewcommand{\arraystretch}{1.25}
% TYPESETTING - MATH
\usepackage{amsmath, amsfonts}
\usepackage[ruled, linesnumbered, noend]{algorithm2e}
\RestyleAlgo{ruled}
% RICH
\usepackage{caption}

% BIBLIOGRAPHY
\usepackage{natbib}
\bibliographystyle{unsrt}

% =======TITLE=======
\title{\vspace*{-0.625in}CS 565: Scientific Computing \\ Project 2: The generation of Heuristic Solutions to Asymmetric and Symmetric Traveling Salesman Problems using Ant Colony Optimization\vspace*{-0.25in}}
\author{Nathan Chapman, Hunter Lawrence, Andrew Struthers}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\pagebreak
\textbf{\textit{Honor code: We pledge that we have neither given nor received help from anyone other than the instructor or the TAs for all work components included here. -- Nathan, Hunter, Andrew}}

\section{Introduction}
    // Introduce the problem
    // Introduce the Algorithm
    // Introduce the implementation
    // Introduce the Results to be found

\section{Traveling Salesman Problem}
    // explain the two kinds of TSP being evaluated, where they are from, the size of the problem. etc.

    \begin{itemize}
        \item Asymmetric TSP
        \item Symmetric TSP
    \end{itemize}

\section{Ant Colony Optimization}

\subsection{Algorithm}
ACO operates by iteratively constructing candidate solutions using a population of virtual ants. Each ant probabilistically selects paths based on the pheromone trails deposited by previous ants. As ants traverse paths, they deposit pheromones, which influence the decisions of subsequent ants. Over time, the concentration of pheromones on promising paths increases, guiding the exploration towards better solutions.

Ant Colony Optimization (ACO) will attempt to iteratively construct better solutions using a number of $a$ ants. These ants will run in parallel, with each making independent randomly-informed travel decisions based on edge weight and the potency of the pheromone left by previous ants on each edge. This probability can be modeled by the following equation given by Yang et al.\cite{yang2008ant}.

\begin{equation}
        \huge p_{ij}^k = 
        \begin{cases}
            \frac{[\tau_{ij}]^\alpha \cdot [\eta_{ij}]^\beta}{\sum_{s\in allowed_k} [\tau_{is}]^\alpha \cdot [\eta_{is}]^\beta} \quad j \in allowed_k\\
            0 \quad\quad\quad\quad\quad\quad\quad\quad \text{otherwise}
        \end{cases}
    \end{equation}

Where $\tau_{ij}$ is the intensity of the pheromone trail between cities $i$ and $j$, $\alpha$ is the parameter to regulate the influence of $\tau_{ij}$, $\eta_{ij}$ is the "visibility" of city $i$ from city $j$ (i.e. how short the distance between the two points are) and is always set to $\frac{1}{d_{ij}}$ (where $d_{ij}$ is the distance between cities $i$ and $j$), $\beta$ is the parameter to regulate the influence of $\eta_{ij}$, and $allowed_k$ is the set of cities that have not yet been visited by the ant in its current iteration:

Once all ants complete a tour, the pheromones of each edge are adjusted before the next iteration begins. First, by evaporating the pheromones on each edge by a constant $\rho$, then adding each ants influence to each edge they traveled on. This can be modeled by the following equation also given by Yang et al.\cite{yang2008ant}


\begin{equation}
        \large \tau_{ij}(t + 1) = \rho \cdot \tau_{ij}(t) + \Delta \tau_{ij}
    \end{equation}

    \begin{equation}
        \large \Delta \tau_{ij} = \sum_{k=1}^l \Delta \tau_{ij}^k
    \end{equation}

    \begin{equation}
        \large \Delta \tau_{ij}^k = 
        \begin{cases}
            \frac{Q}{L_k} \quad \text{if ant k travels on edge (i, j)} \\
            0 \quad\quad \text{otherwise}
        \end{cases}
    \end{equation}

    Where $t$ is the iteration counter, $\rho$ is a real number $[0, 1]$ to regulate the reduction rate of $\tau_{ij}$, $\Delta \tau_{ij}$ is the total increase of trail level on edge $(i, j)$, and $\Delta \tau_{ij}^k$ is the increase of trail level on edge $(i, j)$ caused by ant $k$.

The implementation also depends on a fixed number of iterations before terminating the algorithm. The larger this fixed number of iterations, the more chances the ants have to find a local or global optimum.

Pseudocode for the execution of this algorithm can be seen below
\begin{algorithm}[!h]
    \DontPrintSemicolon
    \caption{Ant Colony Optimization}
    \label{alg:aco}
    \KwResult{}

    Initialize $pheromone\_trails$\;
    Initialize parameters\;
    $best\_solution\gets\{\}$\;
    $iteration\gets0$\;
    \While{$iteration < num\_iterations$}
    {
        \tcc{Construct solutions for each ant}
        \ForEach{$ant\in all\_ants$}
        {
            Initialize ant memory\;
            $visited\_set\gets\{\}$\;
            Randomly select a $start\_node$\;
            Add $start\_node$ to $visited\_set$\;

            \While{$||visited\_set|| < all\_nodes$}
            {
                Probabilistically select next component in solution based on pheromone trails and heuristic information\;
                Update $visited\_set$\;
            }
        
            Apply local search to ant memory\;
            \If{solution is better than $best\_solution$}
            {
                $best\_solution\gets$ solution\;
            }
        }
        Evaporate pheromone trails\;
        Update pheromone trails based on solution quality\;
        $iteration\gets iteration + 1$
    }
    
    \Return{$best\_solution$}
\end{algorithm}
\newpage

\section{Results}
\section{Conclusion}

\pagebreak
\nocite*{}
\bibliography{references}


\end{document}
