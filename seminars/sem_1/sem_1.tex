\documentclass{article}
% =======PACKAGES=======
% FORMATTING
\usepackage[margin=0.625in]{geometry}
\usepackage{parskip, setspace}
\setstretch{1.15}
% TYPESETTING - MATH
\usepackage{amsmath, amsfonts}
\usepackage[ruled, linesnumbered, noend]{algorithm2e}
\usepackage{listings}
\usepackage{xcolor}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{lightgray},   
    commentstyle=\color{darkgray},
    keywordstyle=\color{red},
    numberstyle=\color{black},
    stringstyle=\color{violet},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
% RICH
\usepackage{graphicx, caption}
\usepackage{hyperref}
% BIBLIOGRAPHY
\usepackage[
backend=biber,
sorting=ynt
]{biblatex}
\addbibresource{sem_1.bib}

% =======TITLE=======
\title{\vspace*{-0.625in}CS 565: Scientific Computing \\ Seminar 1: A Survey of Psuedo-Random Number Generators}
\author{Nathan Chapman}
\date{\today}

\begin{document}

    \maketitle

    \section*{Introduction}

        Randomness is a crucial part of scientific computing due to its ability to give deterministic algorithms the ability to adjust in ways they aren't otherwise able.  A notable application of this is in computational optimization.  Though, a problem arises when trying to get a sense of randomness on a machine that is built to be deterministic.  The solution to this problem is in \emph{psuedo}-random number generators (PRNG).

        While computers were built to be deterministic, they still exhibit a source of randomness (i.e. entropy).  Using this source as a PRNG is possible, but too slow for any modern application where the programer needs many generations\cite{WhyNotRandomDevice}.  Because of its need, there have been many developments over the years for more efficient (in some cases \emph{much} more) PRNGs.  What follows is a survey of some of the most employed PRNGs used in scientific computing.
    
    \section*{Methods}

        The standard library of the numerical, scientific computing programming language \emph{Julia} contains two main algorithms to generate psuedo-random numbers\cite{Julia-2017}: \texttt{Xoshiro256++}, and \texttt{MersenneTwister}.  As a historical note, \texttt{Lehmer} generation is also investigated.

        \subsection*{Lehmer}

            The Lhemer PRNG (also known as the Parkâ€“Miller random number generator) is one of the oldest, dating back to the mid 1950s being created by VonNeumann, but it is a simple generator and can still lead to sufficient statistical properties.

            The Lhemer PRNG finds its roots as a linear congruential generator (LCG) taking the form

            \begin{equation*}
                X_{k + 1} = a \cdot X_k \mod m
            \end{equation*}

            where the modulus $m$ is a prime number or a power of a prime number, the multiplier $a$ is an element of high multiplicative order modulo $m$ (e.g., a primitive root modulo $n$), and the seed $X_0$ is coprime to $m$.  One of the most popular implementations is the MINSTD: $m = 2^{31} - 1,\ a = 48271$.

            The Lhemer PRNG shows up in several places including: Julia StableRNGs\cite{StableRNGs}, C++11 as \verb|minstd_rand|, and the GNU Scientific Library\cite{GNUSciLib}.

            This method reached poputlarity due to several factors:
            
            \begin{itemize}
                \item its ability to only use 32-bit arithmetic using Schrage's method; thus being able to be implemented on GPU hardware
                \item It passes Big Crush in TestU01\cite{TestU01}
                \item It is fast and memory efficient (one modulo-m number, often 32 or 64 bits to retain state)
            \end{itemize}

            Though there are some drawbacks:

            \begin{itemize}
                \item It fails the TMFn test from PractRand\cite{Practrand}
                \item A prime modulus implies modular reduction requires a double-width product and an explicit reduction step.
            \end{itemize}

        \subsection*{Xoshiro256++}

            The following statements come from \cite{XoroshiroPaper} or \cite{Shootout}
            \begin{itemize}
                \item xor\_o\_shi\_ro = XOR/shift/rotate
                \item sub ns speed
                \item state space of 256 bits
                \item if you only need 64-bit floats, xoshiro256+ is 15\% faster with the same properties
                \item period of $2^{256} - 1$
                \item provides $2^{128}$ non-overlapping sequences of length $2^{128}$
                \item lowest bits have low linear complexity
                \item xoroshiro128 family is the same speed in half the space (suitable for low-scale parallelism)
                \item xoshiro128 family is 32 bits and thus applicable to be used on GPUs
                \item equidistribution: every n/64-tuple of consecutive 64-bit values appears exactly once in the output, except for the zero tuple (and this is the largest possible dimension).
                \item \href{https://prng.di.unimi.it/xoshiro256plusplus.c}{C code}
                \item platforms: javascript, rust, java, .net, erlang, FORTRAN, julia, lua, IoT (mbed and zephyr)
            \end{itemize}

            \begin{quote}
                \textit{Julia's Xoshiro implementation has a bulk-generation mode; this seeds new virtual PRNGs from the parent, and uses SIMD to generate in parallel (i.e. the bulk stream consists of multiple interleaved xoshiro instances). The virtual PRNGs are discarded once the bulk request has been serviced (and should cause no heap allocations).}
            \end{quote}
        
        \subsection*{MersenneTwister}

            \begin{itemize}
                \item platforms: many programming languages, most notably Python\cite{Python}, Microsoft Excel\cite{Excel}, MATLAB\cite{MATLAB}, C++\cite{Cpp}, Mathematica\cite{Mathematica}, and CUDA\cite{CUDA}
                \item Pros:
                \begin{itemize}
                    \item passes most tests\cite{TestU01}
                    \item very long period $2^{19937} - 1$
                    \item can be used in GPU\cite{MTGP}
                \end{itemize}
                \item Cons:
                    \begin{itemize}
                        \item Relatively large state buffer, of almost 2.5 kB, unless the TinyMT variant (discussed below) is used.
                        \item Mediocre throughput by modern standards, unless the SFMT variant (discussed below) is used\cite{SFMT}.
                        \item Exhibits two clear failures (linear complexity) in both Crush and BigCrush in the TestU01 suite.\cite{TestU01}
                        \item Is not cryptographically secure, unless the CryptMT variant (discussed below) is used. The reason is that observing a sufficient number of iterations (624 in the case of MT19937, since this is the size of the state vector from which future iterations are produced) allows one to predict all future iterations.
                    \end{itemize}
                \item mathematical detail:
                    \begin{itemize}
                        \item For a $w$-bit word length, the Mersenne Twister generates integers in the range $[0, 2^w - 1]$.
                        \item The Mersenne Twister algorithm is based on a matrix linear recurrence over a finite binary field $\mathbf{F}_2$.
                        \item The algorithm is a twisted generalised feedback shift register\cite{TwistedGFSR} (twisted GFSR, or TGFSR) of rational normal form (TGFSR(R)), with state bit reflection and tempering.
                        \item The basic idea is to define a series $x_i$  through a simple recurrence relation, and then output numbers of the form $x_i^T$, where $T$ is an invertible $\mathbf{F}_2$-matrix called a tempering matrix.
                    \end{itemize}
            \end{itemize}

    \section*{Results}

        \begin{itemize}
            \item Show these algorithms in practice
            \item Quality\cite{Shootout}: Compare xoshiro and relatives using BigCrush suite of tests\cite{TestU01} and\cite{HammingWeightDependencies}
            \item Vectorization using AVX2 (Advanced Vector Extensions) vectorization\cite{Shootout}
        \end{itemize}

    \section*{Discussion}

        \begin{itemize}
            \item Compare and contrast each of these algorithms
        \end{itemize}

    \section*{Conclusion}
    
    \newpage
    \printbibliography

\end{document}